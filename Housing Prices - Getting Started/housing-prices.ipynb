{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10211,"databundleVersionId":111096,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Set the Kaggle Notebook to enable automatic code completion\n%config Completer.use_jedi = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:47.812633Z","iopub.execute_input":"2025-06-30T05:36:47.814066Z","iopub.status.idle":"2025-06-30T05:36:47.827726Z","shell.execute_reply.started":"2025-06-30T05:36:47.813979Z","shell.execute_reply":"2025-06-30T05:36:47.826550Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%matplotlib inline\n\nimport os\n\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.utils.data import TensorDataset, DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:47.829646Z","iopub.execute_input":"2025-06-30T05:36:47.830029Z","iopub.status.idle":"2025-06-30T05:36:54.229312Z","shell.execute_reply.started":"2025-06-30T05:36:47.829995Z","shell.execute_reply":"2025-06-30T05:36:54.228530Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Device configuration\nprint(f\"GPU available: {torch.cuda.is_available()}\")\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:54.230166Z","iopub.execute_input":"2025-06-30T05:36:54.230665Z","iopub.status.idle":"2025-06-30T05:36:54.239598Z","shell.execute_reply.started":"2025-06-30T05:36:54.230634Z","shell.execute_reply":"2025-06-30T05:36:54.238621Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"# Load data from .csv by pandas\nbase_path = '/kaggle/input/home-data-for-ml-course'\nlabeled_data = pd.read_csv(os.path.join(base_path, 'train.csv'))\nsubmit_data = pd.read_csv(os.path.join(base_path, 'test.csv'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:54.241376Z","iopub.execute_input":"2025-06-30T05:36:54.241703Z","iopub.status.idle":"2025-06-30T05:36:54.340295Z","shell.execute_reply.started":"2025-06-30T05:36:54.241683Z","shell.execute_reply":"2025-06-30T05:36:54.339457Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# When pandas reads csv, it regards None as NA by default.\n# But in the MasVnrType feature, None represents a specific value, which needs to be restored from NA to None\nlabeled_data['MasVnrType'] = labeled_data['MasVnrType'].fillna('None')\nsubmit_data['MasVnrType'] = submit_data['MasVnrType'].fillna('None')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:54.341207Z","iopub.execute_input":"2025-06-30T05:36:54.341560Z","iopub.status.idle":"2025-06-30T05:36:54.353719Z","shell.execute_reply.started":"2025-06-30T05:36:54.341524Z","shell.execute_reply":"2025-06-30T05:36:54.352782Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f'{labeled_data.shape = }')\nprint(f'{submit_data.shape = }')\nprint(labeled_data.iloc[:4, [0, 1,2, 3, -3, -2, -1]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:54.354928Z","iopub.execute_input":"2025-06-30T05:36:54.355227Z","iopub.status.idle":"2025-06-30T05:36:54.382907Z","shell.execute_reply.started":"2025-06-30T05:36:54.355205Z","shell.execute_reply":"2025-06-30T05:36:54.381856Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Concat the features of the training set and the test set\nall_features = pd.concat((\n    labeled_data.iloc[:, 1:-1],    # Remove the ID features and label from the training sets\n    submit_data.iloc[:, 1:]        # Remove the ID features from the test sets\n))\nlabels = labeled_data.iloc[:, -1]\nsubmit_idxs = submit_data.iloc[:, 0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:54.383792Z","iopub.execute_input":"2025-06-30T05:36:54.384032Z","iopub.status.idle":"2025-06-30T05:36:54.397305Z","shell.execute_reply.started":"2025-06-30T05:36:54.384013Z","shell.execute_reply":"2025-06-30T05:36:54.396287Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data Preprocessing\n\n# 1. Preprocess Numeric Features\n# 1.1 Data Normalization\nnumeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\nall_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))\n# 2.1 Mean Imputation\nall_features[numeric_features] = all_features[numeric_features].fillna(0)\n\n# 2. Preporcess Non-numeric Features\n# The pandas monothermal encoding conversion result is a bool type vector, which will be converted to torch if it is placed in the same table as the numeric type. Tensor Times Error\nall_features = pd.get_dummies(all_features, dummy_na=True).astype(np.float32)   # dummy_na=True, treat 'na' as a valid feature and create an indicator feature for it","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:54.398179Z","iopub.execute_input":"2025-06-30T05:36:54.398510Z","iopub.status.idle":"2025-06-30T05:36:54.481684Z","shell.execute_reply.started":"2025-06-30T05:36:54.398459Z","shell.execute_reply":"2025-06-30T05:36:54.480688Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f'{all_features.shape = }')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:54.482559Z","iopub.execute_input":"2025-06-30T05:36:54.482857Z","iopub.status.idle":"2025-06-30T05:36:54.488356Z","shell.execute_reply.started":"2025-06-30T05:36:54.482830Z","shell.execute_reply":"2025-06-30T05:36:54.487423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Transforms to torch.Tensor\nlabeled_size = labeled_data.shape[0]\nlabeled_features = torch.tensor(all_features[:labeled_size].values, dtype=torch.float32)\nsubmit_features = torch.tensor(all_features[labeled_size:].values, dtype=torch.float32)\nsubmit_idxs = torch.tensor(submit_idxs.values.reshape(-1, 1), dtype=torch.int32)\nlabels = torch.tensor(labels.values.reshape(-1, 1), dtype=torch.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:54.491300Z","iopub.execute_input":"2025-06-30T05:36:54.491602Z","iopub.status.idle":"2025-06-30T05:36:54.555184Z","shell.execute_reply.started":"2025-06-30T05:36:54.491581Z","shell.execute_reply":"2025-06-30T05:36:54.554351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(labeled_features.shape, labels.shape)\nprint(submit_features.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:54.556121Z","iopub.execute_input":"2025-06-30T05:36:54.556450Z","iopub.status.idle":"2025-06-30T05:36:54.562101Z","shell.execute_reply.started":"2025-06-30T05:36:54.556422Z","shell.execute_reply":"2025-06-30T05:36:54.560993Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split labeled data to: 80% for training; 20% for testing;\ntrain_size = int(0.8 * len(labeled_data))\ntrain_features, train_labels = labeled_features[:train_size, :], labels[:train_size, :]\ntest_features, test_labels = labeled_features[train_size:, :], labels[train_size:, :]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:54.563140Z","iopub.execute_input":"2025-06-30T05:36:54.563456Z","iopub.status.idle":"2025-06-30T05:36:54.591710Z","shell.execute_reply.started":"2025-06-30T05:36:54.563427Z","shell.execute_reply":"2025-06-30T05:36:54.590738Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_features.shape, train_labels.shape)\nprint(test_features.shape, test_labels.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:54.592557Z","iopub.execute_input":"2025-06-30T05:36:54.592805Z","iopub.status.idle":"2025-06-30T05:36:54.607716Z","shell.execute_reply.started":"2025-06-30T05:36:54.592787Z","shell.execute_reply":"2025-06-30T05:36:54.606870Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build DataLoader\nbatch_size = 64\ntrain_iter = DataLoader(TensorDataset(train_features, train_labels), batch_size=batch_size, shuffle=True)\ntest_iter = DataLoader(TensorDataset(test_features, test_labels), batch_size=batch_size, shuffle=False)\nlabeled_iter = DataLoader(TensorDataset(labeled_features, labels), batch_size=batch_size, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:54.608589Z","iopub.execute_input":"2025-06-30T05:36:54.608857Z","iopub.status.idle":"2025-06-30T05:36:54.624689Z","shell.execute_reply.started":"2025-06-30T05:36:54.608835Z","shell.execute_reply":"2025-06-30T05:36:54.623765Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Design Model Architecture","metadata":{}},{"cell_type":"code","source":"# Model Hyper-Parameters\ninputs_num, outputs_num = labeled_features.shape[1], labels.shape[1]\nhidden_size1 = 2048\ndropout1 = 0.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:54.625568Z","iopub.execute_input":"2025-06-30T05:36:54.625886Z","iopub.status.idle":"2025-06-30T05:36:54.642165Z","shell.execute_reply.started":"2025-06-30T05:36:54.625861Z","shell.execute_reply":"2025-06-30T05:36:54.640950Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model Architecture\nmlp = nn.Sequential(\n    nn.Linear(inputs_num, hidden_size1),\n    nn.ReLU(),\n    nn.Dropout(dropout1),\n    nn.Linear(hidden_size1, outputs_num),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:54.643114Z","iopub.execute_input":"2025-06-30T05:36:54.643401Z","iopub.status.idle":"2025-06-30T05:36:54.680099Z","shell.execute_reply.started":"2025-06-30T05:36:54.643371Z","shell.execute_reply":"2025-06-30T05:36:54.679191Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train Model","metadata":{}},{"cell_type":"code","source":"# Set Hyper-Parameters\nnum_epochs = 110\nlr = 1e-1\nnet = mlp\nloss = nn.MSELoss()\nweight_decay = 4e-1\noptimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:54.681045Z","iopub.execute_input":"2025-06-30T05:36:54.681292Z","iopub.status.idle":"2025-06-30T05:36:59.095852Z","shell.execute_reply.started":"2025-06-30T05:36:54.681273Z","shell.execute_reply":"2025-06-30T05:36:59.094854Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define RMSE\ndef log_rmse(net, features, labels):\n    clipped_preds = torch.clamp(net(features), 1, float('inf'))\n    rmse = torch.sqrt(loss(torch.log(clipped_preds),\n                           torch.log(labels)))\n    return rmse.item()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:59.097317Z","iopub.execute_input":"2025-06-30T05:36:59.097973Z","iopub.status.idle":"2025-06-30T05:36:59.106868Z","shell.execute_reply.started":"2025-06-30T05:36:59.097938Z","shell.execute_reply":"2025-06-30T05:36:59.105666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Start Training\ndef evaluate_by_test_dataset(net, test_iter):\n    net.eval()    # Set model to evaluating mode\n    trace_data = torch.tensor([0, 0]).type(torch.float32)    # sum[loss]; num[test_sample]\n    with torch.no_grad():\n        for X, y in test_iter:\n            X, y = X, y\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            log_rmse_loss = log_rmse(net, X, y)\n            trace_data += torch.tensor([float(log_rmse_loss) * y.numel(), y.numel()])\n    return trace_data[0] / trace_data[1]    # average[loss]\n\ndef train_epoch(net, train_iter, loss, optimizer):\n    net.train()    # Set model to training mode\n    trace_data = torch.tensor([0, 0]).type(torch.float32)    # sum[loss]; num[train_sample]\n    for X, y in train_iter:\n        X, y = X, y\n        y_hat = net(X)\n        l = loss(y_hat, y)\n        optimizer.zero_grad()\n        l.backward()\n        optimizer.step()\n        log_rmse_loss = log_rmse(net, X, y)\n        trace_data += torch.tensor([float(log_rmse_loss) * y.numel(), y.numel()])\n    return trace_data[0] / trace_data[1]    # average[loss]\n\ndef train_in_training_dataset(net, train_iter, test_iter, loss, optimizer, num_epochs):\n    train_loss_trace, test_loss_trace = [], []\n    for epoch in range(num_epochs):\n        train_loss = train_epoch(net, train_iter, loss, optimizer)\n        test_loss = evaluate_by_test_dataset(net, test_iter)\n        train_loss_trace.append(train_loss)\n        test_loss_trace.append(test_loss)\n        if (epoch + 1) % 5 == 0:\n            print(f\"epoch {epoch + 1:0>{len(str(num_epochs))}}/{num_epochs}: \", end=\"\")\n            print(f\"train_loss {train_loss:>10.8f}, test_loss {test_loss:>10.8f}\")\n    return train_loss_trace, test_loss_trace","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:59.107658Z","iopub.execute_input":"2025-06-30T05:36:59.107955Z","iopub.status.idle":"2025-06-30T05:36:59.133707Z","shell.execute_reply.started":"2025-06-30T05:36:59.107929Z","shell.execute_reply":"2025-06-30T05:36:59.132617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train in splited training dataset\ntrain_loss_trace, test_loss_trace = train_in_training_dataset(net, train_iter, test_iter, loss, optimizer, num_epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:59.134748Z","iopub.execute_input":"2025-06-30T05:36:59.135100Z","iopub.status.idle":"2025-06-30T05:37:31.012017Z","shell.execute_reply.started":"2025-06-30T05:36:59.135073Z","shell.execute_reply":"2025-06-30T05:37:31.010931Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Illustrate train loss and test loss\nepoch_xs = np.arange(1, num_epochs + 1)\nplt.figure(figsize=(8, 5))\nplt.plot(epoch_xs, train_loss_trace, 'bo-', label='Training Loss')\nplt.plot(epoch_xs, test_loss_trace, 'ro-', label='Testing Loss')\nplt.title('Training and Testing Loss over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Log RMSE Loss')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:37:31.013899Z","iopub.execute_input":"2025-06-30T05:37:31.014259Z","iopub.status.idle":"2025-06-30T05:37:31.411724Z","shell.execute_reply.started":"2025-06-30T05:37:31.014233Z","shell.execute_reply":"2025-06-30T05:37:31.410720Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train in total labeled dataset\ndef train_in_labeled_dataset(net, labeled_iter, loss, optimizer, num_epochs):\n    train_loss_trace = []\n    for epoch in range(num_epochs):\n        train_loss = train_epoch(net, labeled_iter, loss, optimizer)\n        train_loss_trace.append(train_loss)\n        if (epoch + 1) % 5 == 0:\n            print(f\"epoch {epoch + 1:0>{len(str(num_epochs))}}/{num_epochs}: \", end=\"\")\n            print(f\"train_loss {train_loss:>10.8f}\")\n    return train_loss_trace\n\ndef reset_weights(m):\n    if hasattr(m, 'reset_parameters'):\n        m.reset_parameters()\n\nnet.apply(reset_weights)\ntrain_loss_trace = train_in_labeled_dataset(net, labeled_iter, loss, optimizer, num_epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:37:31.412698Z","iopub.execute_input":"2025-06-30T05:37:31.413026Z","iopub.status.idle":"2025-06-30T05:38:06.180682Z","shell.execute_reply.started":"2025-06-30T05:37:31.413001Z","shell.execute_reply":"2025-06-30T05:38:06.179298Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generate Submission","metadata":{}},{"cell_type":"code","source":"# Model prediction\ndef predict(net, submit_features):\n    net.eval()\n    with torch.no_grad():\n        rst = net(submit_features)\n    return rst\n\nprediction_rst = predict(net, submit_features).reshape(-1, 1)\nprint(submit_idxs.shape, prediction_rst.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:38:06.181878Z","iopub.execute_input":"2025-06-30T05:38:06.182225Z","iopub.status.idle":"2025-06-30T05:38:06.235930Z","shell.execute_reply.started":"2025-06-30T05:38:06.182200Z","shell.execute_reply":"2025-06-30T05:38:06.234815Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save result to .csv\ndf = pd.DataFrame({\n    'Id': submit_idxs.cpu().numpy().reshape(-1),\n    'SalePrice': prediction_rst.cpu().numpy().reshape(-1),\n})\ndf.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:40:48.648186Z","iopub.execute_input":"2025-06-30T05:40:48.648573Z","iopub.status.idle":"2025-06-30T05:40:48.662543Z","shell.execute_reply.started":"2025-06-30T05:40:48.648546Z","shell.execute_reply":"2025-06-30T05:40:48.661257Z"}},"outputs":[],"execution_count":null}]}